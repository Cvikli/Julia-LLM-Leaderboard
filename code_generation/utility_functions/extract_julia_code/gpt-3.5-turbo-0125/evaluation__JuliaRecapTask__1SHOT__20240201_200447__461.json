{"name":"extract_julia_code","parsed":true,"executed":true,"unit_tests_count":5,"examples_count":4,"unit_tests_passed":1,"examples_executed":2,"tokens":[338,106],"elapsed_seconds":1.044073833,"cost":0.000328,"model":"gpt-3.5-turbo-0125","timestamp":"20240201_200447__461","prompt_strategy":"1SHOT","prompt_label":"JuliaRecapTask","device":"Apple-MacBook-Pro-M1","version_prompt":"1.1","schema":"PromptingTools.OpenAISchema()","version_pt":"0.10.0-DEV","parameters":{},"experiment":""}