{"name":"ispersonal","parsed":true,"executed":false,"unit_tests_count":5,"examples_count":4,"unit_tests_passed":0,"examples_executed":0,"tokens":[413,449],"elapsed_seconds":20.274029042,"cost":0.0,"model":"openhermes2.5-mistral","timestamp":"20231214_073600__896","prompt_strategy":"1SHOT","prompt_label":"JuliaRecapTask","device":"Apple-MacBook-Pro-M1","version_prompt":"1.0","schema":"PromptingTools.OllamaManagedSchema()","version_pt":"0.4.0","parameters":{},"experiment":""}