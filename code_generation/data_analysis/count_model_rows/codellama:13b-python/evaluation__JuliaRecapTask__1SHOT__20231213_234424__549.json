{"name":"count_model_rows","parsed":true,"executed":true,"unit_tests_count":5,"examples_count":2,"unit_tests_passed":0,"examples_executed":0,"tokens":[361,500],"elapsed_seconds":21.3398015,"cost":0.0,"model":"codellama:13b-python","timestamp":"20231213_234424__549","prompt_strategy":"1SHOT","prompt_label":"JuliaRecapTask","device":"Apple-MacBook-Pro-M1","version_prompt":"1.0","schema":"PromptingTools.OllamaManagedSchema()","version_pt":"0.4.0"}